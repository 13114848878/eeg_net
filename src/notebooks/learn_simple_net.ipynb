{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, Activation, Reshape, MaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "from keras import optimizers\n",
    "import sys\n",
    "import keras.utils\n",
    "import os\n",
    "sys.path.append(os.path.join(sys.path[0], '../utils'))\n",
    "from load_mat_file import load_mat_file\n",
    "from keras.callbacks import TensorBoard\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(input_dim, num_classes):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    seq = Sequential()\n",
    "    seq.add(Dense(128, input_shape=(input_dim,)))\n",
    "    seq.add(Activation('relu'));\n",
    "    seq.add(Dropout(0.1))\n",
    "    seq.add(Dense(128, activation='relu'))\n",
    "    seq.add(Dropout(0.1))\n",
    "    seq.add(Dense(num_classes, activation='relu'))\n",
    "    model.add(Activation('softmax'))\n",
    "    return seq\n",
    "\n",
    "\n",
    "def create_network_tu(max_words, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(max_words,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model;\n",
    "\n",
    "\n",
    "def compute_accuracy(predictions, labels):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return labels[predictions.ravel() < 0.5].mean()\n",
    "\n",
    "\n",
    "def create_network_eeg_conv1(input_dim, num_classes):\n",
    "    seq = Sequential()\n",
    "    seq.add(Reshape(( input_dim, 1,), input_shape=(input_dim,)))\n",
    "    seq.add(Conv1D(filters=16, kernel_size=5, activation='relu', strides=2))\n",
    "    seq.add(MaxPooling1D(3, strides=2))\n",
    "    seq.add(Conv1D(32, 5, activation='relu'))\n",
    "    seq.add(MaxPooling1D(3, strides=2))\n",
    "    seq.add(Conv1D(32, 3, activation='relu'))\n",
    "    seq.add(MaxPooling1D(3, strides=2))\n",
    "    seq.add(Conv1D(32, 3, activation='relu'))\n",
    "    seq.add(MaxPooling1D(3, strides=2))\n",
    "    seq.add(GlobalAveragePooling1D())\n",
    "    #seq.add(Reshape(11328,1))\n",
    "    seq.add(Dense(units=128))\n",
    "    seq.add(Activation('relu'));\n",
    "    seq.add(Dense(units=num_classes))\n",
    "    #seq.add(Reshape((num_classes,)))\n",
    "    seq.add(Activation('softmax'));\n",
    "    return seq;\n",
    "\n",
    "def create_network_eeg_conv1_multichannel(input_dim, num_channels, num_classes):\n",
    "    seq = Sequential()\n",
    "    #seq.add(Reshape(( input_dim, 1,), input_shape=(input_dim,)))\n",
    "    seq.add(Conv1D(filters=64, kernel_size=5, activation='relu', strides=2, input_shape=(input_dim,num_channels,)))\n",
    "    seq.add(MaxPooling1D(3, strides=2))\n",
    "    seq.add(Conv1D(32, 5, activation='relu'))\n",
    "    seq.add(MaxPooling1D(3, strides=2))\n",
    "    seq.add(Conv1D(32, 3, activation='relu'))\n",
    "    seq.add(MaxPooling1D(3, strides=2))\n",
    "    seq.add(Conv1D(32, 3, activation='relu'))\n",
    "    seq.add(MaxPooling1D(3, strides=2))\n",
    "    seq.add(GlobalAveragePooling1D())\n",
    "    #seq.add(Reshape(11328,1))\n",
    "    seq.add(Dense(units=128))\n",
    "    seq.add(Activation('relu'));\n",
    "    seq.add(Dense(units=num_classes))\n",
    "    #seq.add(Reshape((num_classes,)))\n",
    "    seq.add(Activation('softmax'));\n",
    "    return seq;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_mc_small(input_dim, num_channels, num_classes):\n",
    "    seq = Sequential()\n",
    "    #seq.add(Reshape(( input_dim, 1,), input_shape=(input_dim,)))\n",
    "    seq.add(Conv1D(filters=64, kernel_size=5, activation='relu', strides=2, input_shape=(input_dim,num_channels,)))\n",
    "    seq.add(MaxPooling1D(3, strides=2))\n",
    "    seq.add(Conv1D(32, 5, activation='relu'))\n",
    "    seq.add(MaxPooling1D(3, strides=2))\n",
    "    #seq.add(Conv1D(32, 3, activation='relu'))\n",
    "    #seq.add(MaxPooling1D(3, strides=2))\n",
    "    #seq.add(Conv1D(32, 3, activation='relu'))\n",
    "    #seq.add(MaxPooling1D(3, strides=2))\n",
    "    print (seq.output_shape)\n",
    "    seq.add(Reshape((seq.output_shape[1]*seq.output_shape[2]) ))\n",
    "    seq.add(GlobalAveragePooling1D())\n",
    "    #seq.add(Reshape(11328,1))\n",
    "    seq.add(Dense(units=128))\n",
    "    seq.add(Activation('relu'));\n",
    "    seq.add(Dense(units=num_classes))\n",
    "    #seq.add(Reshape((num_classes,)))\n",
    "    seq.add(Activation('softmax'));\n",
    "    return seq;\n",
    "\n",
    "model = create_cnn_mc_small(size_of_sample, number_of_channels, num_classes)\n",
    "#model = create_network_eeg_conv1_multichannel(size_of_sample, number_of_channels, num_classes)\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    EXP_NUM = 21 # total number of people\n",
    "    EXP_SHIFT = 167 # shift in numerations\n",
    "    CHANNELS_NUM = 21 # number of channels in EEG record\n",
    "    sel_channels = slice(14, 18)\n",
    "    all_data = np.array([])\n",
    "    all_Y = np.array([])\n",
    "    for eeg_num in range(1, EXP_NUM + 1):\n",
    "        EEG_FILENAME = 'eegmat_selected/D0000' + str(eeg_num + EXP_SHIFT)\n",
    "        EEG = load_mat_file(EEG_FILENAME, 's')\n",
    "        X_data = EEG[\"eeg\"][0][0]\n",
    "        X_data = np.swapaxes(X_data, 2, 0)\n",
    "        X_data = np.swapaxes(X_data, 1, 2)\n",
    "        Y_data = EEG[\"mrk\"][0][0]\n",
    "        OneChannel_data = X_data[:, sel_channels, :]\n",
    "        OneChannel_data = OneChannel_data.reshape(OneChannel_data.shape[0], OneChannel_data.shape[1]*OneChannel_data.shape[2])\n",
    "        if eeg_num == 1:\n",
    "            all_data = np.array([]).reshape(0, OneChannel_data.shape[1])\n",
    "            all_Y = np.array([]).reshape(0, Y_data.shape[1])\n",
    "        all_data = np.concatenate([all_data, OneChannel_data])\n",
    "        all_Y = np.concatenate([all_Y, Y_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data(data_path):\n",
    "    EXP_NUM = 21 # total number of people\n",
    "    EXP_SHIFT = 167 # shift in numerations\n",
    "    CHANNELS_NUM = 21 # number of channels in EEG record\n",
    "    sel_channels = slice(14, 18)\n",
    "    all_data = np.array([])\n",
    "    all_Y = np.array([])\n",
    "    for eeg_num in range(1, EXP_NUM + 1):\n",
    "        EEG_FILENAME = 'eegmat_selected/D0000' + str(eeg_num + EXP_SHIFT)\n",
    "        EEG = load_mat_file(os.path.join(data_path,EEG_FILENAME), 's')\n",
    "        X_data = EEG[\"eeg\"][0][0]\n",
    "        \n",
    "        X_data = np.swapaxes(X_data, 2, 0)\n",
    "        X_data = np.swapaxes(X_data, 1, 2)\n",
    "        Y_data = EEG[\"mrk\"][0][0]\n",
    "        OneChannel_data = X_data[:, sel_channels, :]\n",
    "        OneChannel_data = OneChannel_data.reshape(OneChannel_data.shape[0], OneChannel_data.shape[1]*OneChannel_data.shape[2])\n",
    "        if eeg_num == 1:\n",
    "            all_data = np.array([]).reshape(0, OneChannel_data.shape[1])\n",
    "            all_Y = np.array([]).reshape(0, Y_data.shape[1])\n",
    "        all_data = np.concatenate([all_data, OneChannel_data])\n",
    "        all_Y = np.concatenate([all_Y, Y_data])\n",
    "    return all_data, all_Y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(X_data, Y_data, indx, channels):\n",
    "    sample = X_data[indx];\n",
    "    label = Y_data[indx];\n",
    "    f, ax = plt.subplots(figsize=(8, 8))\n",
    "    x = range(0, sample.shape[0]);\n",
    "    for i in channels:\n",
    "        plt.plot(x, sample[:,i])\n",
    "        \n",
    "    ax.legend(['ch ' + repr(i) for i in channels])\n",
    "    ax.set_title('stimulus numer: ' + repr(indx) + ', label: ' + repr(Y_data[indx]));\n",
    "    ax.set_xlabel('time, ticks')\n",
    "    ax.set_ylabel('voltage')\n",
    "        #x = range(0, sample.shape[0])\n",
    "        #plt.xlabel('milliseconds');\n",
    "        #plt.ylabel('volatage');\n",
    "        \n",
    "        #ax.plot(acc_levels, acc_perc, color='steelblue', label='perceptron')\n",
    "        #ax.plot(acc_levels, acc_lstm, color='orangered', label='lstm, exp avg')\n",
    "        #ax.plot(acc_levels, acc_lstm_2, color='orangered', label='lstm, 0 pred', linestyle='--')\n",
    "        # ax.plot(acc_levels, acc_merged, color='seagreen')\n",
    "\n",
    "\n",
    "        #ax.set_xlabel(\"Distance between predicted and actual dot\")\n",
    "        #ax.set_ylabel(\"Amount of predictions within the distance\")\n",
    "        # plt.vlines([0.1, 0.2, 0.3], 0, 1, label=\"within 0.1 of screen size\", colors='gray', linestyles='--')\n",
    "        # plt.hlines([0.25, 0.5, 0.75], 0, 1, label=\"within 0.1 of screen size\", colors='gray', linestyles='--')\n",
    "\n",
    "        #ax.grid(which='both')                                                            \n",
    "\n",
    "        # or if you want differnet settings for the grids:                               \n",
    "        #ax.grid(which='minor', alpha=0.1)                                                \n",
    "        #ax.grid(which='major', alpha=0.5)   \n",
    "        #ax.minorticks_on()\n",
    "        #plt.legend()\n",
    "\n",
    "#show_data(X_data, Y_data, 2, [0,18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data_multichannel(data_path):\n",
    "    EXP_NUM = 21 # total number of people\n",
    "    EXP_SHIFT = 167 # shift in numerations\n",
    "    CHANNELS_NUM = 21 # number of channels in EEG record\n",
    "    sel_channels = slice(0, 18)\n",
    "    sel_time = slice(0,60,1) #quanta time\n",
    "    all_data = np.array([])\n",
    "    all_Y = np.array([])\n",
    "    for eeg_num in range(1, EXP_NUM + 1):\n",
    "        EEG_FILENAME = 'eegmat_selected/D0000' + str(eeg_num + EXP_SHIFT)\n",
    "        EEG = load_mat_file(os.path.join(data_path,EEG_FILENAME), 's')\n",
    "        X_data = EEG[\"eeg\"][0][0]\n",
    "        #print(X_data[:,:,1])\n",
    "        #print(X_data.shape)\n",
    "        X_data = np.swapaxes(X_data, 2, 0)\n",
    "        X_data = np.swapaxes(X_data, 1, 2)\n",
    "        \n",
    "        Y_data = EEG[\"mrk\"][0][0]\n",
    "        #show_data(X_data, Y_data, 1, [0,2])\n",
    "        OneChannel_data = X_data[:, sel_time, sel_channels]\n",
    "        #OneChannel_data = OneChannel_data.reshape(OneChannel_data.shape[0], OneChannel_data.shape[1]*OneChannel_data.shape[2])\n",
    "        if eeg_num == 1:\n",
    "            all_data = np.array([]).reshape(0, OneChannel_data.shape[1], OneChannel_data.shape[2])\n",
    "            all_Y = np.array([]).reshape(0, Y_data.shape[1])\n",
    "        all_data = np.concatenate([all_data, OneChannel_data])\n",
    "        all_Y = np.concatenate([all_Y, Y_data])\n",
    "    return all_data, all_Y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/workspace/data/eeg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 3703\n",
      "time counts: 60\n",
      "number_of_channels: 4\n",
      "num_classes:  2\n"
     ]
    }
   ],
   "source": [
    "X_data, Y_data = load_all_data_multichannel(data_path);\n",
    "number_of_samples = X_data.shape[0];\n",
    "size_of_sample = X_data.shape[1];\n",
    "number_of_channels = X_data.shape[2];\n",
    "\n",
    "print('number of samples:', number_of_samples)\n",
    "print('time counts:', size_of_sample)\n",
    "print('number_of_channels:', number_of_channels)\n",
    "\n",
    "Y_data = Y_data - 1;\n",
    "Y_data = Y_data.reshape(Y_data.shape[0])\n",
    "num_classes = int(max(Y_data) + 1);\n",
    "print('num_classes: ', num_classes)\n",
    "y_= keras.utils.to_categorical(Y_data, int(num_classes));\n",
    "show_data(X_data, Y_data, [1,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_= X_data;\n",
    "test_prop = 0.1;\n",
    "test_size= round(test_prop * number_of_samples, 0);\n",
    "test_size = int(test_size)\n",
    "train_size = number_of_samples - test_size;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size:  3333\n",
      "test size:  370\n"
     ]
    }
   ],
   "source": [
    "#random shuffle of dataset and train-test split\n",
    "idx = np.random.choice(np.arange(x_.shape[0]), x_.shape[0], replace=False)\n",
    "idx_train = idx[0:train_size]\n",
    "idx_test = idx[train_size:]\n",
    "print('train size: ', train_size)\n",
    "print('test size: ', test_size)\n",
    "y_train = y_[idx_train];\n",
    "x_train = x_[idx_train];\n",
    "y_test= y_[idx_test];\n",
    "x_test= x_[idx_test];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3333, 275, 21)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 2)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_44 (Conv1D)           (None, 28, 64)            1344      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 13, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 9, 32)             10272     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 4, 32)             0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_11  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 16,098\n",
      "Trainable params: 16,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = create_cnn_mc_small(size_of_sample, number_of_channels, num_classes)\n",
    "#model = create_network_eeg_conv1_multichannel(size_of_sample, number_of_channels, num_classes)\n",
    "print(model.summary())\n",
    "#model = create_network_tu(size_of_sample, num_classes)\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2666 samples, validate on 667 samples\n",
      "Epoch 1/5\n",
      "2666/2666 [==============================] - 2s 601us/step - loss: 0.6995 - acc: 0.5023 - val_loss: 0.6996 - val_acc: 0.4903\n",
      "Epoch 2/5\n",
      "2666/2666 [==============================] - ETA: 0s - loss: 0.6980 - acc: 0.501 - 2s 565us/step - loss: 0.6981 - acc: 0.5011 - val_loss: 0.6994 - val_acc: 0.4798\n",
      "Epoch 3/5\n",
      "2666/2666 [==============================] - 2s 564us/step - loss: 0.6975 - acc: 0.5041 - val_loss: 0.6992 - val_acc: 0.4843\n",
      "Epoch 4/5\n",
      "2666/2666 [==============================] - 1s 563us/step - loss: 0.6971 - acc: 0.5030 - val_loss: 0.6991 - val_acc: 0.4843\n",
      "Epoch 5/5\n",
      "2666/2666 [==============================] - 2s 565us/step - loss: 0.6968 - acc: 0.5019 - val_loss: 0.6991 - val_acc: 0.4858\n",
      "370/370 [==============================] - 0s 198us/step\n",
      "[0.7115293821773013, 0.4432432417934005]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20;\n",
    "epochs = 5;\n",
    "sgd = optimizers.Adagrad(lr=0.00001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True)\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[tensorboard])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
